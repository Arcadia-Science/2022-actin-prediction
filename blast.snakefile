import pandas as pd
import os

rule all:
    input: "qpa_done.txt"

rule blast:
    input: "inputs/P60709_ACTB_HUMAN.fasta"
    output: "outputs/blast/blastp_results.out"
    conda: "envs/blast.yml"
    shell:'''
    blastp -db nr -query {input} -out {output} -remote -max_target_seqs 50000 -outfmt 6
    '''

checkpoint determine_query_protein_accessions:
    '''
    checkpoints instruct snakemake to re-evaluate the DAG mid-workflow.
    This allows us to create a new wildcard from information generated by the workflow itself.
    Originally I wrote this part of the workflow to combine the checkpoint step with the download step.
    However, this made it so that all of the protein fasta files would need to be downloaded on a single thread.
    This would take a long time when running it against all 50k BLASTP results.
    I updated the workflow so that the checkpoint generates empty files that have the protein accessions in them, thereby solving the wildcard but not performing the download.
    The wildcard can then be used to download the fastas in the next rule and allow the download to be parallelized.
    '''
    input: "outputs/blast/blastp_results.out"
    output: directory("outputs/blast/query_protein_fastas/")
    run:
        # check if output director exists, and if not, create it
        outdir = output[0]
        check_outdir_exists = os.path.isdir(outdir)
        if not check_outdir_exists:
            os.makedirs(outdir)

        # read in blast results, iterate through the matched protein accessions, and download as fastas
        blastp_results = pd.read_csv(str(input[0]), header = None, sep = "\t")
        query_protein_accessions = blastp_results[1].unique().tolist()
        for query_protein_accession in query_protein_accessions:
            # make these temporary empty files.
            output_file = "." + query_protein_accession + ".txt"
            output_path = os.path.join("outputs", "blast", "query_protein_fastas", output_file)
            shell('touch {output_path}') 


rule download_query_protein_fastas:
    input: "outputs/blast/query_protein_fastas/.{query_protein_accession}.txt"
    output: "query_proteins/{query_protein_accession}.fasta"
    conda: "envs/entrez-direct.yml"
    benchmark: "benchmarks/download_query_protein_fastas/{query_protein_accession}.txt"
    shell:'''
    esearch -db protein -query "{wildcards.query_protein_accession}" | efetch -format fasta > {output}
    '''

def checkpoint_determine_query_protein_accessions(wildcards):
    # Expand checkpoint to get fasta names, which will be used as query proteins for the main Snakefile
    # checkpoint_output encodes the output dir from the checkpoint rule.
    checkpoint_output = checkpoints.determine_query_protein_accessions.get(**wildcards).output[0]    
    file_names = expand("query_proteins/{query_protein_accession}.fasta",
                        query_protein_accession = glob_wildcards(os.path.join(checkpoint_output, ".{query_protein_accession}.txt")).query_protein_accession)
    return file_names


rule collapse_tmp:
    input: checkpoint_determine_query_protein_accessions
    output: touch("qpa_done.txt")
